{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adarsh/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "import pymssql\n",
    "import pandas as pd\n",
    "import json\n",
    "import multiprocessing as mp\n",
    "import datetime\n",
    "import pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "server = '192.168.4.117'\n",
    "database = 'FreedomCashLenders'\n",
    "username = 'FreedomCashLendersAll'\n",
    "mssql_password = 'Freedom123$'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "iloans_conn = pymssql.connect(server, username, mssql_password, database, port = 1433)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = \"'2018-01-01'\"\n",
    "end_date = \"'2019-12-31'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_loan = f'''select LN.LoanId,\n",
    "                       LC.LoanCount,\n",
    "                       LN.OriginationDate,\n",
    "                       GC.BankReportData,\n",
    "                       GC.TimeAdded as ReportTimeAdded,\n",
    "                       LN.Campaign,\n",
    "                       LN.MonthlyGrossIncome,\n",
    "                       LN.DateOfBirth,\n",
    "                       LN.IsFirstDefault\n",
    "                       \n",
    "                from view_FCL_Loan LN\n",
    "                LEFT JOIN view_FCL_CustomerLoanCount LC ON LC.CustomerId = LN.CustomerId\n",
    "                LEFT JOIN view_FCL_GetCreditDataLoan GCD ON LN.LoanId = GCD.LoanId\n",
    "                LEFT JOIN view_FCL_GetCreditData GC ON GC.BankTransactionId = GCD.BankTransactionId\n",
    "                \n",
    "                \n",
    "                where LN.OriginationDate >= {start_date}\n",
    "                and LN.OriginationDate <= {end_date} \n",
    "                and LN.IsFirstDefault IS NOT NULL\n",
    "                and LN.MerchantId IN (15, 18)\n",
    "                and GC.ReportStatus = 'COMPLETE' '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loans = pd.read_sql_query(query_loan,con = iloans_conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loans = df_loans.drop_duplicates('LoanId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_esign = f'''\n",
    "SELECT\n",
    "    LN.LoanId,\n",
    "    ESIG.AccessCount,\n",
    "    ESIG.EsigTimeSignedDiff_In_SEC\n",
    "FROM\n",
    "    view_FCL_Loan LN\n",
    "    LEFT JOIN view_FCL_EsignatureCustomerData ESIG ON LN.LoanId = ESIG.LoanId\n",
    "WHERE\n",
    "    LN.OriginationDate >= {start_date} \n",
    "    and LN.OriginationDate <= {end_date}\n",
    "    and LN.IsFirstDefault IS NOT NULL\n",
    "    and LN.MerchantId IN (15, 18)\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_esign = pd.read_sql_query(query_esign,con=iloans_conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Data for Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stringify_account_ids(loan_id_list):\n",
    "    \"\"\"\n",
    "    Convert account_id list into comma-separated string of account_ids\n",
    "    :return: string containing comma-separated account_ids\n",
    "    \"\"\"\n",
    "    return '(' + ', '.join([str(i) for i in loan_id_list]) + ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loanid_string=stringify_account_ids(loan_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_loan_eval = '''select LN.LoanId,\n",
    "                       LC.LoanCount,\n",
    "                       LN.OriginationDate,\n",
    "                       GC.BankReportData,\n",
    "                       GC.TimeAdded as ReportTimeAdded,\n",
    "                       LN.Campaign,\n",
    "                       LN.MonthlyGrossIncome,\n",
    "                       LN.DateOfBirth,\n",
    "                       LN.IsFirstDefault\n",
    "                       \n",
    "                from view_FCL_Loan LN\n",
    "                LEFT JOIN view_FCL_CustomerLoanCount LC ON LC.CustomerId = LN.CustomerId\n",
    "                LEFT JOIN view_FCL_GetCreditDataLoan GCD ON LN.LoanId = GCD.LoanId\n",
    "                LEFT JOIN view_FCL_GetCreditData GC ON GC.BankTransactionId = GCD.BankTransactionId\n",
    "                \n",
    "                \n",
    "                WHERE\n",
    "                    GC.ReportStatus = 'COMPLETE'\n",
    "                    AND LN.LoanId IN %s'''%(loanid_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loan_eval = pd.read_sql_query(query_loan_eval,con=iloans_conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loan_eval=df_loan_eval.drop_duplicates('LoanId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_esign_eval = '''\n",
    "SELECT\n",
    "    LN.LoanId,\n",
    "    ESIG.AccessCount,\n",
    "    ESIG.EsigTimeSignedDiff_In_SEC\n",
    "FROM\n",
    "    view_FCL_Loan LN\n",
    "    LEFT JOIN view_FCL_EsignatureCustomerData ESIG ON LN.LoanId = ESIG.LoanId\n",
    "WHERE\n",
    "    LN.LoanId IN %s'''%(loanid_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_esign_eval = pd.read_sql_query(query_esign_eval,con=iloans_conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_esign_eval=df_esign_eval.drop_duplicates('LoanId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_dates(json_date):\n",
    "    '''\n",
    "    Converts json formatted date to pandas datetime.\n",
    "    \n",
    "    Parameters:\n",
    "    JSON date (JSON).\n",
    "    \n",
    "    Returns:\n",
    "    Pandas datetime object.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    #return datetime.fromtimestamp(int(json_date)/1000.0).strftime('%Y-%m-%d')\n",
    "    return datetime.datetime.utcfromtimestamp(int(json_date)/1000).date()\n",
    "\n",
    "\n",
    "def fetch_checking_acct_txns(json_string):\n",
    "    \"\"\"\n",
    "    Parse all checking account transactions in the bank report\n",
    "    \n",
    "    Parameters:\n",
    "    json_string(json): json containing bank report\n",
    "    \n",
    "    Returns:\n",
    "    dataframe: containing transactions \n",
    "    \n",
    "    \"\"\"\n",
    "    j = json.loads(json_string)\n",
    "    df_txn = pd.DataFrame()\n",
    "    \n",
    "    acct_numbers = []\n",
    "    for accts in j['accounts']:\n",
    "        \n",
    "        if ('transactions' in accts.keys()) and (len(accts['transactions']) > 0) and (accts['accountNumber'] not in acct_numbers) and (accts['accountType'].strip().lower() == 'checking'):\n",
    "            \n",
    "            df_txn_temp = pd.DataFrame(accts['transactions'])\n",
    "            df_txn_temp['account_number'] = accts['accountNumber']\n",
    "            df_txn = df_txn.append(df_txn_temp, ignore_index=True)\n",
    "            \n",
    "            df_txn['posted_date'] = df_txn['postedDate'].map(lambda json_date: parse_dates(json_date))\n",
    "            df_txn['category'] = df_txn['contexts'].map(lambda x: x[0]['categoryName'] if len(x) > 0 else np.nan)\n",
    "            acct_numbers.append(accts['accountNumber'])\n",
    "    \n",
    "    if 'pending' in df_txn.columns:\n",
    "        df_txn = df_txn[df_txn['pending'] == False]\n",
    "    return df_txn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## primary account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_primary_account(bankreport):\n",
    "    \"\"\"\n",
    "    Flag primary checking account (account having max transaction count)\n",
    "    \n",
    "    Parameters:\n",
    "    bankreport (json)\n",
    "    loanid (str)\n",
    "    \n",
    "    Returns:\n",
    "    Dataframe containing checking accounts and primary account flag = 1\n",
    "    \"\"\"\n",
    "    df_txn = fetch_checking_acct_txns(bankreport)\n",
    "    if df_txn.empty is False:\n",
    "        df_txns_count = df_txn['account_number'].value_counts()\n",
    "        return df_txns_count.idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NCPU = mp.cpu_count() - 2 if mp.cpu_count() > 2 else 1\n",
    "with mp.Pool(processes=NCPU) as pool:\n",
    "    res_primary_accts = pool.map(get_primary_account, df_loans['BankReportData'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loans['primary_account'] = res_primary_accts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loans = df_loans.loc[df_loans['primary_account'].notnull(),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## filter loans having transaction days >= 60 in primary account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transaction_days_count(primary_account,bank_report):\n",
    "    df_checking_txns = fetch_checking_acct_txns(bank_report)\n",
    "    if df_checking_txns.empty is False:\n",
    "        df_primary_account_txns = df_checking_txns[df_checking_txns['account_number']==primary_account]\n",
    "        df_primary_account_txns= df_primary_account_txns.sort_values(by='posted_date')\n",
    "        first_txn_date = df_primary_account_txns['posted_date'].iloc[0]\n",
    "        last_txn_date = df_primary_account_txns['posted_date'].iloc[-1]\n",
    "        txn_days_count = (last_txn_date - first_txn_date).days\n",
    "        return txn_days_count >= 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NCPU = mp.cpu_count() - 2 if mp.cpu_count() > 2 else 1\n",
    "with mp.Pool(processes=NCPU) as pool:\n",
    "    txn_days_count = pool.starmap(get_transaction_days_count, zip(df_loans['primary_account'],df_loans['BankReportData']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loans['txn_days_count'] = txn_days_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loans = df_loans.loc[df_loans['txn_days_count'] == True, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_age(current_date, dob):\n",
    "    age = len(pd.date_range(start=dob,end=current_date,freq='Y'))\n",
    "    return age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loans['Age'] = df_loans.apply(lambda x: calculate_age(x['OriginationDate'],x['DateOfBirth']), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New or Reloan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loans['Reloan'] = df_loans['LoanCount'].apply(lambda x:True if x>1 else False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lead Provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loans = df_loans.loc[df_loans['Campaign'].notnull(),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_provider_list=['MarketBullet','StopNGo','Nimbus','EPCVIP','PingBid','LeapThry',\n",
    "'Acquir','RoundSky','Zero','LeadPie',\n",
    "'ITMedia','LeadsMarket']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loans['LeadProvider'] = df_loans['Campaign'].str.extract(\"(\" + \"|\".join(lead_provider_list) +\")\",flags = re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loans['LeadProvider']=df_loans['LeadProvider'].fillna('Freedom')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lender vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lender_vars(loanid,report_string,time_added,pr_acct):\n",
    "\n",
    "        \"\"\"\n",
    "        Function to generate lender variables \n",
    "        from primary account transactions\n",
    "\n",
    "        Paramaters:\n",
    "            txns(Boolean): True - Return lender txns along with lender variables\n",
    "                           False - Return only lender variables\n",
    "\n",
    "        Returns:\n",
    "            lender_vars(dictionary): Dictionary containing all lender variables\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        lender_vars = dict()   \n",
    "        lender_vars['LoanId'] = loanid\n",
    "        lender_vars['LenderAmountDeb'] = 0.0\n",
    "        lender_vars['LenderCountCred'] = 0.0\n",
    "        lender_vars['LenderAmountCred30'] = 0.0\n",
    "        lender_vars['LenderCountDeb'] = 0.0\n",
    "        lender_vars['LenderAmountDeb30'] = 0.0\n",
    "        lender_vars['LenderCountCred30'] = 0.0\n",
    "        lender_vars['LenderCountDeb30'] = 0.0\n",
    "        lender_vars['LenderAmountCred'] = 0.0\n",
    "        lender_vars['UniqLenderCount'] = 0.0\n",
    "\n",
    "        #load lending company list\n",
    "        lend_cos=joblib.load('./lend_cos.pkl')\n",
    "\n",
    "        #get primary checking account transactions\n",
    "        df_checking_txns = fetch_checking_acct_txns(report_string) \n",
    "        df_pr_acct_txns = df_checking_txns[df_checking_txns['account_number']==pr_acct]\n",
    "        \n",
    "        \n",
    "        #prepare lender transactions dataframe\n",
    "        df_lender_txns=df_pr_acct_txns.loc[df_pr_acct_txns['memo'].str.contains('|'.join(lend_cos),case=False,na=False)]\n",
    "        \n",
    "        #check for empty transactions\n",
    "        if df_lender_txns.empty is False:\n",
    "            df_lender_txns['lenderName'] = df_lender_txns['memo'].str.extract(\"(\" + \"|\".join(lend_cos) +\")\",flags = re.IGNORECASE)\n",
    "            df_lender_txns['days_diff'] = (time_added.date()-df_lender_txns['posted_date']).dt.days\n",
    "            df_lender_txns['amount'] = df_lender_txns['amount'].round(2)\n",
    "\n",
    "\n",
    "            #conditions to determine lender variables\n",
    "            cond1 = (df_lender_txns['amount']>0)\n",
    "            cond2 = cond1 & (df_lender_txns['days_diff']<=30)\n",
    "            cond3 = (df_lender_txns['amount']<0)\n",
    "            cond4 = cond3 & (df_lender_txns['days_diff']<=30)\n",
    "\n",
    "            #prepare lender variables\n",
    "            lender_vars['LenderAmountDeb'] = float(df_lender_txns.loc[cond3,'amount'].sum())\n",
    "            lender_vars['LenderCountCred'] = float(df_lender_txns[cond1].shape[0])\n",
    "            lender_vars['LenderAmountCred30'] = float(df_lender_txns.loc[cond2,'amount'].sum())\n",
    "            lender_vars['LenderCountDeb'] = float(df_lender_txns[cond3].shape[0])\n",
    "            lender_vars['LenderAmountDeb30'] = float(df_lender_txns.loc[cond4,'amount'].sum())\n",
    "            lender_vars['LenderCountCred30'] = float(df_lender_txns.loc[cond2].shape[0])\n",
    "            lender_vars['LenderCountDeb30'] = float(df_lender_txns.loc[cond4].shape[0])\n",
    "            lender_vars['LenderAmountCred'] = float(df_lender_txns.loc[cond1,'amount'].sum())\n",
    "            lender_vars['UniqLenderCount'] = float(df_lender_txns['lenderName'].nunique())\n",
    "\n",
    "        return pd.DataFrame(lender_vars,index=[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### in case the lender vars are to be generated for funded loans between 2018-01-01 to 2019-12-31 do not run the below cell, instead download from s3 ( look for \"download lender vars from s3\" markdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lender_vars = pd.DataFrame()\n",
    "NCPU = mp.cpu_count() - 2 if mp.cpu_count() > 2 else 1\n",
    "with mp.Pool(processes=NCPU) as pool:\n",
    "    df_lender_vars_temp = pool.starmap(create_lender_vars, zip(df_loans['LoanId'],df_loans['BankReportData'],df_loans['ReportTimeAdded'],df_loans['primary_account']))\n",
    "df_lender_vars=pd.concat(df_lender_vars_temp,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lender_vars.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### download lender vars from s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#provide access keys if needed\n",
    "s3 = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.download_file('predicon-bucket', 'lender_vars.csv', 'FILE_NAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lender_vars = pd.read_csv('lender_vars.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loans = pd.merge(df_loans,df_lender_vars,how='left',on='LoanId')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### esign variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loans= pd.merge(df_loans,df_esign,on='LoanId',how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## useful links\n",
    "https://docs.databricks.com/_static/notebooks/mlflow/mlflow-quick-start-deployment-aws.html\n",
    "\n",
    "https://towardsdatascience.com/deploying-models-to-production-with-mlflow-and-amazon-sagemaker-d21f67909198\n",
    "\n",
    "https://www.h2o.ai/blog/a-deep-dive-into-h2os-automl/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## specify features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_drop = ['LoanCount',\n",
    "'OriginationDate',             \n",
    "'BankReportData',                   \n",
    "'ReportTimeAdded',                  \n",
    "'Campaign',\n",
    "'primary_account',\n",
    "'txn_days_count', 'DateOfBirth',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_loans.drop(columns=features_drop,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "h2o.init(max_mem_size='16G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_h20_train =  h2o.H2OFrame(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = \"IsFirstDefault\" \n",
    "x = df_h20_train.columns\n",
    "x.remove(y)\n",
    "x.remove('LoanId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aml = H2OAutoML(max_runtime_secs=120, seed=1)\n",
    "aml.train(x=x, y=y, training_frame=df_h20_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = aml.leaderboard\n",
    "lb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### primary account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NCPU = mp.cpu_count() - 2 if mp.cpu_count() > 2 else 1\n",
    "with mp.Pool(processes=NCPU) as pool:\n",
    "    res_primary_accts = pool.map(get_primary_account, df_loan_eval['BankReportData'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loan_eval['primary_account'] = res_primary_accts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filter loans having transaction days >= 60 in primary account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NCPU = mp.cpu_count() - 2 if mp.cpu_count() > 2 else 1\n",
    "with mp.Pool(processes=NCPU) as pool:\n",
    "    txn_days_count = pool.starmap(get_transaction_days_count, zip(df_loan_eval['primary_account'],df_loan_eval['BankReportData']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loan_eval['txn_days_count'] = txn_days_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loan_eval = df_loan_eval.loc[df_loan_eval['txn_days_count']==True,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loan_eval['Age'] = df_loan_eval.apply(lambda x: calculate_age(x['OriginationDate'],x['DateOfBirth']), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lead provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loan_eval = df_loan_eval.loc[df_loan_eval['Campaign'].notnull(),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loan_eval['LeadProvider'] = df_loan_eval['Campaign'].str.extract(\"(\" + \"|\".join(lead_provider_list) +\")\",flags = re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loan_eval['LeadProvider']=df_loan_eval['LeadProvider'].fillna('Freedom')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### new or reloan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loan_eval['Reloan'] = df_loan_eval['LoanCount'].apply(lambda x:True if x>1 else False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lender vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lender_vars_eval = pd.DataFrame()\n",
    "NCPU = mp.cpu_count() - 2 if mp.cpu_count() > 2 else 1\n",
    "with mp.Pool(processes=NCPU) as pool:\n",
    "    df_lender_vars_temp = pool.starmap(create_lender_vars, zip(df_loan_eval['LoanId'],df_loan_eval['BankReportData'],df_loan_eval['ReportTimeAdded'],df_loan_eval['primary_account']))\n",
    "df_lender_vars_eval=pd.concat(df_lender_vars_temp,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loan_eval = pd.merge(df_loan_eval,df_lender_vars_eval,on='LoanId',how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### esign variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loan_eval= pd.merge(df_loan_eval,df_esign_eval,on='LoanId',how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loan_predict = df_loan_eval.drop(columns=features_drop,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2o_eval = h2o.H2OFrame(df_loan_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = aml.leader.predict(h2o_eval)\n",
    "pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to pandas dataframe\n",
    "df_predictions = h2o.as_list(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loan_eval.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions['target'] = df_loan_eval['IsFirstDefault']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions = df_predictions.rename(columns={'True':'prob'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions = df_predictions[['target','prob']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions['target'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get BV uncertain and BV Approved loans for model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "username_bank_app = 'bankreview'\n",
    "password_bank_app = 'Freedom!23'\n",
    "host_bank_app = '192.168.4.115'\n",
    "port_bank_app = 3306\n",
    "db_bank_app = 'bankreviewdb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_app_conn = pymysql.connect(host=host_bank_app,\n",
    "                                port=port_bank_app,\n",
    "                                db=db_bank_app,\n",
    "                                user=username_bank_app,\n",
    "                                password=password_bank_app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_evaluation_loans = '''select loan_id, \n",
    "                                final_decision,\n",
    "                                reasons_for_decision,\n",
    "                                entered_date\n",
    "                                \n",
    "                            from loan \n",
    "                            where campaign like '%Production%'\n",
    "                            and STR_TO_DATE(entered_date ,'%m/%d/%Y') >= STR_TO_DATE('01/01/2020','%m/%d/%Y')\n",
    "                            and STR_TO_DATE(entered_date ,'%m/%d/%Y') < STR_TO_DATE('04/01/2020','%m/%d/%Y')\n",
    "                            and final_decision in ('Bank Validation Uncertain','Bank Validation Approved') '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval_loans = pd.read_sql_query(query_evaluation_loans, con = bank_app_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get funded and mature loans for the same period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_funded_mature_loans = ''' select LoanId, \n",
    "                                IsFirstDefault\n",
    "                        from view_FCL_Loan\n",
    "                        where OriginationDate >= '2020-01-01' \n",
    "                        and OriginationDate <= '2020-03-31'\n",
    "                        and IsFirstDefault IS NOT NULL\n",
    "                        and MerchantId IN (15, 18)\n",
    "                        \n",
    "                     '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_funded_mature_loans = pd.read_sql_query(query_funded_mature_loans,con = iloans_conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_funded_mature_loans['LoanId'] = df_funded_mature_loans['LoanId'].astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval = pd.merge(df_funded_mature_loans,df_eval_loans,how = 'inner',left_on = 'LoanId',right_on = 'loan_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1199 entries, 0 to 1198\n",
      "Data columns (total 6 columns):\n",
      "LoanId                  1199 non-null object\n",
      "IsFirstDefault          1199 non-null bool\n",
      "loan_id                 1199 non-null object\n",
      "final_decision          1199 non-null object\n",
      "reasons_for_decision    1199 non-null object\n",
      "entered_date            1199 non-null object\n",
      "dtypes: bool(1), object(5)\n",
      "memory usage: 57.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_eval.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_id_list = list(df_eval['LoanId'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute KS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_KS(df_pred):\n",
    "    \"\"\"\n",
    "    Returns KS given scores\n",
    "    Parameters:\n",
    "    df_pred (pandas df): DataFrame containing target variable and model score\n",
    "    \n",
    "    Returns:\n",
    "    float: KS value\n",
    "    \"\"\"\n",
    "    df_scores = df_predictions.sort_values(by='prob')\n",
    "    total_good = (df_scores['target'] == False).sum()\n",
    "    total_bad = (df_scores['target'] == True).sum()\n",
    "    df_scores['cum_good_perc'] = (df_scores['target'] == False).cumsum()/total_good\n",
    "    df_scores['cum_bad_perc'] = (df_scores['target'] == True).cumsum()/total_bad\n",
    "    df_scores['cum_diff'] = np.abs((df_scores['cum_good_perc'] - df_scores['cum_bad_perc']))\n",
    "    return df_scores['cum_diff'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_KS()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### quantiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_table(df_pred,n = 10):\n",
    "    \"\"\"\n",
    "    Returns a quantile table given model scores (default is decile)\n",
    "    \n",
    "    Parameters:\n",
    "    df_pred (pandas df): DataFrame containing target variable and model score\n",
    "    \n",
    "    Returns:\n",
    "    pandas DataFrame: Pandas dataframe containing quantiles\n",
    "    \n",
    "    \"\"\"\n",
    "    df_scores = df_predictions.sort_values(by='prob')\n",
    "    df_scores['decile'],score_bin = pd.qcut(df_scores['prob'],10,labels=[1,2,3,4,5,6,7,8,9,10],retbins = True)\n",
    "    df_scores['target'] = df_scores['target'].astype(int)\n",
    "    df_scores_deciles = df_scores.groupby('decile',as_index=False).agg({'prob':['count','min','max','mean'],'target':'sum'})\n",
    "    df_scores_deciles.columns = ['decile','count','min_score','max_score','mean_score','bad_count']\n",
    "    df_scores_deciles['perc_bad'] = (df_scores_deciles['bad_count']/df_scores_deciles['count']) * 100\n",
    "    return df_scores_deciles,score_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile_table, score_bins = quantile_table(df_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get bins for quantile assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_bins = np.concatenate(([-np.inf], score_bins, [np.inf]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### upload to sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow.h2o as mh2o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow.sagemaker as mfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mh2o.save_model(aml.leader,path=\"path/to/trained/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = \"us-east-1\"\n",
    "arn = \"arn:aws:iam::757719720041:role/Sagemaker\"\n",
    "appname = \"h20-mlflow-deploy\"\n",
    "modeluri = \"path/to/saved/model\" \n",
    "image_url = \"757719720041.dkr.ecr.us-east-1.amazonaws.com/freedom-pyfunc:latest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfs.deploy(app_name=appname, model_uri=modeluri, instance_type='ml.t2.medium',region_name=region, mode=\"create\",execution_role_arn=arn,image_url=image_url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
